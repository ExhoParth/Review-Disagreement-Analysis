{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:26.103038Z",
     "iopub.status.busy": "2024-12-02T07:44:26.102482Z",
     "iopub.status.idle": "2024-12-02T07:44:26.424038Z",
     "shell.execute_reply": "2024-12-02T07:44:26.423206Z",
     "shell.execute_reply.started": "2024-12-02T07:44:26.103005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/test-review-pairs/review_pairs_dataset.csv\n",
      "/kaggle/input/review-pairs-dataset/dnnlp_project_dataset.csv\n",
      "/kaggle/input/dt_pairs/pytorch/default/1/final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:26.706826Z",
     "iopub.status.busy": "2024-12-02T07:44:26.706445Z",
     "iopub.status.idle": "2024-12-02T07:44:29.577840Z",
     "shell.execute_reply": "2024-12-02T07:44:29.577175Z",
     "shell.execute_reply.started": "2024-12-02T07:44:26.706798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:29.580276Z",
     "iopub.status.busy": "2024-12-02T07:44:29.579662Z",
     "iopub.status.idle": "2024-12-02T07:44:29.590385Z",
     "shell.execute_reply": "2024-12-02T07:44:29.589614Z",
     "shell.execute_reply.started": "2024-12-02T07:44:29.580236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CrossEncoderCSR(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"roberta-base\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize encoder\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.encoder_config = self.encoder.config\n",
    "        self.total_layers = len(self.encoder.encoder.layer)\n",
    "\n",
    "        self.d_k = self.encoder_config.hidden_size\n",
    "\n",
    "    def forward(self, s1_input_ids, s1_attention_mask, s2_input_ids, s2_attention_mask, c_input_ids, c_attention_mask):\n",
    "        # Encode context\n",
    "        c_output = self.encoder(c_input_ids, c_attention_mask, output_hidden_states=True)\n",
    "        c_hidden_state = c_output.last_hidden_state  # Shape: (B, L_c, H)\n",
    "\n",
    "        # Obtain query vector for the condition (last hidden state pooled)\n",
    "        q_c = c_hidden_state[:, 0, :]  # Use [CLS] token as the query vector (B, H)\n",
    "\n",
    "        # Start with token embeddings for s1 and s2\n",
    "        s1_hidden_state = self.encoder.embeddings(s1_input_ids)\n",
    "        s2_hidden_state = self.encoder.embeddings(s2_input_ids)\n",
    "\n",
    "        # Process up to the t-th layer\n",
    "        for i in range(self.total_layers):\n",
    "            layer = self.encoder.encoder.layer[i]\n",
    "            \n",
    "            # Ensure attention masks are float tensors\n",
    "            s1_attention_mask = s1_attention_mask.to(dtype=torch.float)\n",
    "            s2_attention_mask = s2_attention_mask.to(dtype=torch.float)\n",
    "\n",
    "            # s1_attention_mask = s1_attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "            # s2_attention_mask = s2_attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "            \n",
    "            # Original multi-head attention hidden states\n",
    "            s1_hidden_state = layer(s1_hidden_state, attention_mask=s1_attention_mask.unsqueeze(1).unsqueeze(2))[0]  # (B, L_s, H)\n",
    "            s2_hidden_state = layer(s2_hidden_state, attention_mask=s2_attention_mask.unsqueeze(1).unsqueeze(2))[0]  # (B, L_s, H)\n",
    "            \n",
    "            if i >= self.total_layers // 2:  # Introduce router from t-th layer onwards\n",
    "                # Get key vectors for current layer\n",
    "                k_s1 = s1_hidden_state  # (B, L_s, H)\n",
    "                k_s2 = s2_hidden_state  # (B, L_s, H)\n",
    "\n",
    "                # Compute router weights\n",
    "                s1_w_t = self.get_c_router_weights(q_c, k_s1)  # (B, L_s)\n",
    "                s2_w_t = self.get_c_router_weights(q_c, k_s2)  # (B, L_s)\n",
    "\n",
    "                # Adjust multi-head attention hidden state\n",
    "                s1_hidden_state = (1 + s1_w_t.unsqueeze(-1)) * s1_hidden_state  # (B, L_s, H)\n",
    "                s2_hidden_state = (1 + s2_w_t.unsqueeze(-1)) * s2_hidden_state  # (B, L_s, H)\n",
    "\n",
    "        # Average pooling for final sentence representation\n",
    "        s1_representation = s1_hidden_state.mean(dim=1)  # Shape: (B, H)\n",
    "        s2_representation = s2_hidden_state.mean(dim=1)  # Shape: (B, H)\n",
    "\n",
    "        return s1_representation, s2_representation\n",
    "\n",
    "    def get_c_router_weights(self, q_c, k_s):\n",
    "        \"\"\"\n",
    "        Compute attention weights using the formula:\n",
    "        score = (q_c * k_s) / sqrt(d_k)\n",
    "        w = softmax(score)\n",
    "        \"\"\"\n",
    "        # Normalize q_c and k_s\n",
    "        q_c = q_c.unsqueeze(1)  # Shape: (B, 1, H)\n",
    "        scores = torch.matmul(q_c, k_s.transpose(-2, -1))  # Shape: (B, 1, L_s)\n",
    "        scores = scores / torch.sqrt(torch.tensor(self.d_k, dtype=torch.float32))  # Scale scores\n",
    "        \n",
    "        # Softmax to get router weights\n",
    "        weights = nn.functional.softmax(scores, dim=-1)  # Shape: (B, 1, L_s)\n",
    "        return weights.squeeze(1)  # Shape: (B, L_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:29.591692Z",
     "iopub.status.busy": "2024-12-02T07:44:29.591354Z",
     "iopub.status.idle": "2024-12-02T07:44:31.098026Z",
     "shell.execute_reply": "2024-12-02T07:44:31.097113Z",
     "shell.execute_reply.started": "2024-12-02T07:44:29.591655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c804a37d2c64498abe0a0d85f08331c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0694fab9ed40e0a480c471d9264203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec6463fe9ce4bd6b252f085cbcd7751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee08a681f3da45feb54a98c49f8d145f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbe3fcc06f747f4b2f4cb6bc157024e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer initialization\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Custom Dataset class\n",
    "class ContradictionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        s1, s2, aspect, label = row['sentence1'], row['sentence2'], row['aspect'], row['label']\n",
    "\n",
    "        # Tokenize inputs\n",
    "        s1_tokens = self.tokenizer(s1, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        s2_tokens = self.tokenizer(s2, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "        aspect_tokens = self.tokenizer(aspect, truncation=True, padding=\"max_length\", max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "        # Map label to binary value\n",
    "        label = 1 if label == \"c\" else 0\n",
    "\n",
    "        return {\n",
    "            \"s1_input_ids\": s1_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"s1_attention_mask\": s1_tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"s2_input_ids\": s2_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"s2_attention_mask\": s2_tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"aspect_input_ids\": aspect_tokens[\"input_ids\"].squeeze(0),\n",
    "            \"aspect_attention_mask\": aspect_tokens[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:31.100024Z",
     "iopub.status.busy": "2024-12-02T07:44:31.099750Z",
     "iopub.status.idle": "2024-12-02T07:44:31.416655Z",
     "shell.execute_reply": "2024-12-02T07:44:31.415740Z",
     "shell.execute_reply.started": "2024-12-02T07:44:31.099998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>premise</th>\n",
       "      <th>aspect</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>line_pair</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ICLR_2019_1401</td>\n",
       "      <td>3</td>\n",
       "      <td>further the paper makes several misleading cla...</td>\n",
       "      <td>the paper is rather well written but it strong...</td>\n",
       "      <td>clarity</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>(6, 2)</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NIPS_2016_89</td>\n",
       "      <td>3</td>\n",
       "      <td>4 .i like the key idea and the speedup is very...</td>\n",
       "      <td>review scores reflect this reviewers impressio...</td>\n",
       "      <td>originality</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>(5, 20)</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NIPS_2016_89</td>\n",
       "      <td>4</td>\n",
       "      <td>the idea to use sampling is nice but the analy...</td>\n",
       "      <td>review scores reflect this reviewers impressio...</td>\n",
       "      <td>originality</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>(5, 18)</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NIPS_2016_89</td>\n",
       "      <td>5</td>\n",
       "      <td>to summarize i think this paper give some empi...</td>\n",
       "      <td>in my opinion the overall quality of the paper...</td>\n",
       "      <td>soundness</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>(4, 10)</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NIPS_2016_89</td>\n",
       "      <td>5</td>\n",
       "      <td>to summarize i think this paper give some empi...</td>\n",
       "      <td>the context and relevance as well as the contr...</td>\n",
       "      <td>soundness</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        paper_id  pair_id  \\\n",
       "0             0           0  ICLR_2019_1401        3   \n",
       "1             1           1    NIPS_2016_89        3   \n",
       "2             2           2    NIPS_2016_89        4   \n",
       "3             3           3    NIPS_2016_89        5   \n",
       "4             4           4    NIPS_2016_89        5   \n",
       "\n",
       "                                          hypothesis  \\\n",
       "0  further the paper makes several misleading cla...   \n",
       "1  4 .i like the key idea and the speedup is very...   \n",
       "2  the idea to use sampling is nice but the analy...   \n",
       "3  to summarize i think this paper give some empi...   \n",
       "4  to summarize i think this paper give some empi...   \n",
       "\n",
       "                                             premise       aspect        s1  \\\n",
       "0  the paper is rather well written but it strong...      clarity  positive   \n",
       "1  review scores reflect this reviewers impressio...  originality  negative   \n",
       "2  review scores reflect this reviewers impressio...  originality  negative   \n",
       "3  in my opinion the overall quality of the paper...    soundness  positive   \n",
       "4  the context and relevance as well as the contr...    soundness  positive   \n",
       "\n",
       "         s2 line_pair label  \n",
       "0  negative    (6, 2)     n  \n",
       "1  positive   (5, 20)     n  \n",
       "2  positive   (5, 18)     n  \n",
       "3  negative   (4, 10)     n  \n",
       "4  negative   (5, 10)     n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/review-pairs-dataset/dnnlp_project_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:31.417924Z",
     "iopub.status.busy": "2024-12-02T07:44:31.417645Z",
     "iopub.status.idle": "2024-12-02T07:44:31.423561Z",
     "shell.execute_reply": "2024-12-02T07:44:31.422718Z",
     "shell.execute_reply.started": "2024-12-02T07:44:31.417898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'paper_id', 'pair_id', 'hypothesis',\n",
       "       'premise', 'aspect', 's1', 's2', 'line_pair', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:31.476217Z",
     "iopub.status.busy": "2024-12-02T07:44:31.475877Z",
     "iopub.status.idle": "2024-12-02T07:44:31.489613Z",
     "shell.execute_reply": "2024-12-02T07:44:31.488706Z",
     "shell.execute_reply.started": "2024-12-02T07:44:31.476180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/190843048.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.rename(columns={'hypothesis': 'sentence1', 'premise': 'sentence2'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "final_df = df[['hypothesis', 'premise', 'aspect', 'label']]\n",
    "final_df.rename(columns={'hypothesis': 'sentence1', 'premise': 'sentence2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:31.560158Z",
     "iopub.status.busy": "2024-12-02T07:44:31.559942Z",
     "iopub.status.idle": "2024-12-02T07:44:31.569026Z",
     "shell.execute_reply": "2024-12-02T07:44:31.568020Z",
     "shell.execute_reply.started": "2024-12-02T07:44:31.560135Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>aspect</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>further the paper makes several misleading cla...</td>\n",
       "      <td>the paper is rather well written but it strong...</td>\n",
       "      <td>clarity</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 .i like the key idea and the speedup is very...</td>\n",
       "      <td>review scores reflect this reviewers impressio...</td>\n",
       "      <td>originality</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the idea to use sampling is nice but the analy...</td>\n",
       "      <td>review scores reflect this reviewers impressio...</td>\n",
       "      <td>originality</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to summarize i think this paper give some empi...</td>\n",
       "      <td>in my opinion the overall quality of the paper...</td>\n",
       "      <td>soundness</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to summarize i think this paper give some empi...</td>\n",
       "      <td>the context and relevance as well as the contr...</td>\n",
       "      <td>soundness</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  further the paper makes several misleading cla...   \n",
       "1  4 .i like the key idea and the speedup is very...   \n",
       "2  the idea to use sampling is nice but the analy...   \n",
       "3  to summarize i think this paper give some empi...   \n",
       "4  to summarize i think this paper give some empi...   \n",
       "\n",
       "                                           sentence2       aspect label  \n",
       "0  the paper is rather well written but it strong...      clarity     n  \n",
       "1  review scores reflect this reviewers impressio...  originality     n  \n",
       "2  review scores reflect this reviewers impressio...  originality     n  \n",
       "3  in my opinion the overall quality of the paper...    soundness     n  \n",
       "4  the context and relevance as well as the contr...    soundness     n  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:32.398186Z",
     "iopub.status.busy": "2024-12-02T07:44:32.397838Z",
     "iopub.status.idle": "2024-12-02T07:44:32.402477Z",
     "shell.execute_reply": "2024-12-02T07:44:32.401449Z",
     "shell.execute_reply.started": "2024-12-02T07:44:32.398140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:33.304764Z",
     "iopub.status.busy": "2024-12-02T07:44:33.304422Z",
     "iopub.status.idle": "2024-12-02T07:44:33.373914Z",
     "shell.execute_reply": "2024-12-02T07:44:33.373153Z",
     "shell.execute_reply.started": "2024-12-02T07:44:33.304734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:34.801514Z",
     "iopub.status.busy": "2024-12-02T07:44:34.801134Z",
     "iopub.status.idle": "2024-12-02T07:44:39.567045Z",
     "shell.execute_reply": "2024-12-02T07:44:39.566213Z",
     "shell.execute_reply.started": "2024-12-02T07:44:34.801484Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25c61f910334094ac8e982b5c10d663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrossEncoderCSR(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 3\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_data, val_data = train_test_split(final_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = ContradictionDataset(train_data, tokenizer, max_length=MAX_LENGTH)\n",
    "val_dataset = ContradictionDataset(val_data, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "model = CrossEncoderCSR(model_name)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:39.569054Z",
     "iopub.status.busy": "2024-12-02T07:44:39.568619Z",
     "iopub.status.idle": "2024-12-02T07:44:39.582185Z",
     "shell.execute_reply": "2024-12-02T07:44:39.581233Z",
     "shell.execute_reply.started": "2024-12-02T07:44:39.569026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "\n",
    "def train_model(\n",
    "    model, train_loader, val_loader, optimizer, criterion, epochs, device, \n",
    "    save_path=\"model_checkpoints\", save_interval=1\n",
    "):\n",
    "    os.makedirs(save_path, exist_ok=True)  # Create directory for saving models\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "        train_progress = tqdm(train_loader, desc=\"Training\", leave=False)  # Training progress bar\n",
    "        \n",
    "        for batch in train_progress:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Move batch to device\n",
    "            s1_input_ids = batch[\"s1_input_ids\"].to(device)\n",
    "            s1_attention_mask = batch[\"s1_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "            s2_input_ids = batch[\"s2_input_ids\"].to(device)\n",
    "            s2_attention_mask = batch[\"s2_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "            aspect_input_ids = batch[\"aspect_input_ids\"].to(device)\n",
    "            aspect_attention_mask = batch[\"aspect_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            s1_rep, s2_rep = model(\n",
    "                s1_input_ids, s1_attention_mask, \n",
    "                s2_input_ids, s2_attention_mask, \n",
    "                aspect_input_ids, aspect_attention_mask\n",
    "            )\n",
    "            \n",
    "            # Compute similarity\n",
    "            logits = torch.cosine_similarity(s1_rep, s2_rep, dim=1).unsqueeze(1)\n",
    "            logits = torch.cat([1 - logits, logits], dim=1)  # Binary classification logits\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            train_progress.set_postfix(loss=loss.item())  # Update progress bar\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "        \n",
    "        # Save checkpoint at specified intervals\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(save_path, f\"model_epoch_{epoch + 1}.pth\")\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        val_progress = tqdm(val_loader, desc=\"Validation\", leave=False)  # Validation progress bar\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_progress:\n",
    "                s1_input_ids = batch[\"s1_input_ids\"].to(device)\n",
    "                s1_attention_mask = batch[\"s1_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "                s2_input_ids = batch[\"s2_input_ids\"].to(device)\n",
    "                s2_attention_mask = batch[\"s2_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "                aspect_input_ids = batch[\"aspect_input_ids\"].to(device)\n",
    "                aspect_attention_mask = batch[\"aspect_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "                \n",
    "                s1_rep, s2_rep = model(\n",
    "                    s1_input_ids, s1_attention_mask, \n",
    "                    s2_input_ids, s2_attention_mask, \n",
    "                    aspect_input_ids, aspect_attention_mask\n",
    "                )\n",
    "                \n",
    "                logits = torch.cosine_similarity(s1_rep, s2_rep, dim=1).unsqueeze(1)\n",
    "                logits = torch.cat([1 - logits, logits], dim=1)\n",
    "                \n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                val_progress.set_postfix(val_loss=loss.item())  # Update progress bar\n",
    "        \n",
    "        accuracy = correct / len(val_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss / len(val_loader)}, Accuracy: {accuracy}\")\n",
    "    \n",
    "    # Save final model\n",
    "    final_model_path = os.path.join(\"/kaggle/working/\", \"final_model.pth\")\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Final model saved at {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T08:43:54.130207Z",
     "iopub.status.busy": "2024-11-30T08:43:54.129387Z",
     "iopub.status.idle": "2024-11-30T11:31:52.618359Z",
     "shell.execute_reply": "2024-11-30T11:31:52.617407Z",
     "shell.execute_reply.started": "2024-11-30T08:43:54.130162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.47004190404233065\n",
      "Checkpoint saved at model_checkpoints/model_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1938494140187366, Accuracy: 0.1194372068785826\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Loss: 0.45292725171896747\n",
      "Checkpoint saved at model_checkpoints/model_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1938494087644351, Accuracy: 0.1194372068785826\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Loss: 0.4497786504760261\n",
      "Checkpoint saved at model_checkpoints/model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1938494123790964, Accuracy: 0.1194372068785826\n",
      "Final model saved at /kaggle/working/final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# train_model(model, train_loader, val_loader, optimizer, criterion, EPOCHS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:39.608829Z",
     "iopub.status.busy": "2024-12-02T07:44:39.608613Z",
     "iopub.status.idle": "2024-12-02T07:44:39.627958Z",
     "shell.execute_reply": "2024-12-02T07:44:39.627185Z",
     "shell.execute_reply.started": "2024-12-02T07:44:39.608806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review1</th>\n",
       "      <th>Review2</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Contradictory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The usability of this Cloud Computing system i...</td>\n",
       "      <td>The usability of this Machine Learning system ...</td>\n",
       "      <td>usability</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The usability of this AI system is remarkable.</td>\n",
       "      <td>The usability of this Cybersecurity system is ...</td>\n",
       "      <td>usability</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The reliability of this AI system is excellent.</td>\n",
       "      <td>The reliability of this Cybersecurity system i...</td>\n",
       "      <td>reliability</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The reliability of this Cloud Computing system...</td>\n",
       "      <td>The reliability of this Data Science system is...</td>\n",
       "      <td>reliability</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The scalability of this Cybersecurity system i...</td>\n",
       "      <td>The scalability of this Cloud Computing system...</td>\n",
       "      <td>scalability</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Review1  \\\n",
       "0  The usability of this Cloud Computing system i...   \n",
       "1     The usability of this AI system is remarkable.   \n",
       "2    The reliability of this AI system is excellent.   \n",
       "3  The reliability of this Cloud Computing system...   \n",
       "4  The scalability of this Cybersecurity system i...   \n",
       "\n",
       "                                             Review2       Aspect  \\\n",
       "0  The usability of this Machine Learning system ...    usability   \n",
       "1  The usability of this Cybersecurity system is ...    usability   \n",
       "2  The reliability of this Cybersecurity system i...  reliability   \n",
       "3  The reliability of this Data Science system is...  reliability   \n",
       "4  The scalability of this Cloud Computing system...  scalability   \n",
       "\n",
       "   Contradictory  \n",
       "0          False  \n",
       "1           True  \n",
       "2          False  \n",
       "3           True  \n",
       "4          False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/test-review-pairs/review_pairs_dataset.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:40.505796Z",
     "iopub.status.busy": "2024-12-02T07:44:40.505122Z",
     "iopub.status.idle": "2024-12-02T07:44:40.510314Z",
     "shell.execute_reply": "2024-12-02T07:44:40.509367Z",
     "shell.execute_reply.started": "2024-12-02T07:44:40.505761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.rename(columns={'Review1': 'sentence1', 'Review2': 'sentence2', 'Aspect': 'aspect', 'Contradictory': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:44:41.306573Z",
     "iopub.status.busy": "2024-12-02T07:44:41.306234Z",
     "iopub.status.idle": "2024-12-02T07:44:41.310643Z",
     "shell.execute_reply": "2024-12-02T07:44:41.309878Z",
     "shell.execute_reply.started": "2024-12-02T07:44:41.306543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def func(val):\n",
    "    if val:\n",
    "        return 'c'\n",
    "    else :\n",
    "        return 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:45:10.611875Z",
     "iopub.status.busy": "2024-12-02T07:45:10.611542Z",
     "iopub.status.idle": "2024-12-02T07:45:10.616732Z",
     "shell.execute_reply": "2024-12-02T07:45:10.615869Z",
     "shell.execute_reply.started": "2024-12-02T07:45:10.611844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df['label'] = test_df['label'].apply(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:45:49.901597Z",
     "iopub.status.busy": "2024-12-02T07:45:49.901262Z",
     "iopub.status.idle": "2024-12-02T07:45:49.906215Z",
     "shell.execute_reply": "2024-12-02T07:45:49.905312Z",
     "shell.execute_reply.started": "2024-12-02T07:45:49.901569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "test_data = ContradictionDataset(test_df, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T07:45:50.812035Z",
     "iopub.status.busy": "2024-12-02T07:45:50.811706Z",
     "iopub.status.idle": "2024-12-02T07:46:32.817987Z",
     "shell.execute_reply": "2024-12-02T07:46:32.817117Z",
     "shell.execute_reply.started": "2024-12-02T07:45:50.812004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_30/3700499873.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /kaggle/input/dt_pairs/pytorch/default/1/final_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model, checkpoint_path, device):\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {checkpoint_path}\")\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    test_progress = tqdm(test_loader, desc=\"Testing\", leave=False)  # Testing progress bar\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_progress:\n",
    "            # Move batch to device\n",
    "            s1_input_ids = batch[\"s1_input_ids\"].to(device)\n",
    "            s1_attention_mask = batch[\"s1_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "            s2_input_ids = batch[\"s2_input_ids\"].to(device)\n",
    "            s2_attention_mask = batch[\"s2_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "            aspect_input_ids = batch[\"aspect_input_ids\"].to(device)\n",
    "            aspect_attention_mask = batch[\"aspect_attention_mask\"].to(dtype=torch.float).to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            s1_rep, s2_rep = model(\n",
    "                s1_input_ids, s1_attention_mask, \n",
    "                s2_input_ids, s2_attention_mask, \n",
    "                aspect_input_ids, aspect_attention_mask\n",
    "            )\n",
    "            \n",
    "            # Compute similarity and logits\n",
    "            logits = torch.cosine_similarity(s1_rep, s2_rep, dim=1).unsqueeze(1)\n",
    "            logits = torch.cat([1 - logits, logits], dim=1)\n",
    "            \n",
    "            # Predictions\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return precision, recall, f1, accuracy\n",
    "\n",
    "# Example Usage\n",
    "# Replace `YourModelClass` with your actual model class\n",
    "# Replace `test_loader` with your DataLoader for the test dataset\n",
    "# Replace `model_checkpoint.pth` with your actual .pth file path\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CrossEncoderCSR()  # Initialize your model architecture\n",
    "checkpoint_path = \"/kaggle/input/dt_pairs/pytorch/default/1/final_model.pth\"\n",
    "\n",
    "# Load model weights\n",
    "load_model(model, checkpoint_path, device)\n",
    "\n",
    "# Evaluate the model\n",
    "precision, recall, f1, accuracy = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T06:37:20.417475Z",
     "iopub.status.busy": "2024-12-02T06:37:20.417100Z",
     "iopub.status.idle": "2024-12-02T06:37:22.188115Z",
     "shell.execute_reply": "2024-12-02T06:37:22.187212Z",
     "shell.execute_reply.started": "2024-12-02T06:37:20.417446Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'The cat sit on mat' and 'The mat is covered by cat': 0.9815711975097656\n"
     ]
    }
   ],
   "source": [
    "def test_cross_encoder_csr():\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    # Create model\n",
    "    model = CrossEncoderCSR(model_name=\"roberta-base\")\n",
    "    \n",
    "    # Prepare test inputs\n",
    "    sentences1 = [\"The cat sit on mat\"]\n",
    "    sentences2 = [\"The mat is covered by cat\"]\n",
    "    context = [\"Test123\"]\n",
    "    \n",
    "    # Tokenize inputs\n",
    "    s1_inputs = tokenizer(sentences1, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    s2_inputs = tokenizer(sentences2, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    c_inputs = tokenizer(context, padding='max_length', truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        s1_hidden, s2_hidden = model(\n",
    "            s1_input_ids=s1_inputs['input_ids'], \n",
    "            s1_attention_mask=s1_inputs['attention_mask'].to(dtype=torch.float),\n",
    "            s2_input_ids=s2_inputs['input_ids'], \n",
    "            s2_attention_mask=s2_inputs['attention_mask'].to(dtype=torch.float),\n",
    "            c_input_ids=c_inputs['input_ids'], \n",
    "            c_attention_mask=c_inputs['attention_mask'].to(dtype=torch.float)\n",
    "        )\n",
    "    \n",
    "    # print(\"S1 Hidden States Shape:\", s1_hidden)\n",
    "    # print(\"S2 Hidden States Shape:\", s2_hidden)\n",
    "    \n",
    "    # Optional: Compute cosine similarity\n",
    "    def cosine_similarity(a, b):\n",
    "        return torch.nn.functional.cosine_similarity(a, b, dim=-1)\n",
    "    \n",
    "    # Compute and print similarity\n",
    "    for i in range(len(sentences1)):\n",
    "        sim = cosine_similarity(s1_hidden[i], s2_hidden[i])\n",
    "        print(f\"Similarity between '{sentences1[i]}' and '{sentences2[i]}': {sim.item()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_cross_encoder_csr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T17:29:47.422468Z",
     "iopub.status.busy": "2024-11-27T17:29:47.421562Z",
     "iopub.status.idle": "2024-11-27T17:29:47.429726Z",
     "shell.execute_reply": "2024-11-27T17:29:47.428615Z",
     "shell.execute_reply.started": "2024-11-27T17:29:47.422422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original tensor\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Add a new dimension at dim=0\n",
    "x_unsqueezed = x.unsqueeze(0)\n",
    "\n",
    "print(x_unsqueezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6194088,
     "sourceId": 10052683,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6209432,
     "sourceId": 10073818,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 180383,
     "modelInstanceId": 157984,
     "sourceId": 185318,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
